# Generative AI

It is a subfield of AI. These are AI systems that create new content, such as images, text or audio. In context of AI these systems are called **Models**.

Generative AI models are trained on extensive datasets, where they learn to recognize patterns and structures present in the training data. These models find applications in diverse areas, including image synthesis, text generation, and music composition.

## Fields

- **NLP**
- **Computer Vision**

## Models

- LLM's (Large Language Models)
- Diffusion Models

## NLP

### LLM's

LLM's are used for textual data and studied under **NLP** (Natural Language Processing).

**Example:**

- **GPT** (Generative Pre-trained Transformer)

## Computer Vision

### Diffusion Models

Diffusion models are used for images specifically and are studied under **Computer Vision**.

**Example:**

- **Dall-e-2**
- **Dall-e-3**

## Difference between Multi-models and Foundational models

### 1. Foundational Models

**Foundational models** are large-scale artificial intelligence models trained on massive amounts of data. They are designed to be versatile and can be adapted to perform a wide range of tasks, such as **language translation**, **text generation**, and **image recognition**. These models are the foundation for many modern AI applications and have significantly advanced the capabilities of generative AI.

### 2. Multi-modal Models

**Multi-modal models** are AI models that can process and understand multiple types of data simultaneously. This includes text, images, audio, and video. They are capable of integrating information from different modalities to perform complex tasks like **image captioning**, **video understanding**, and **question answering**.
