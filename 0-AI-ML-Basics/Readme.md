# Artificial Intelligence (AI)

Artificial Intelligence (AI) is a broad field of computer science that focuses on creating systems capable of performing tasks that typically require human intelligence. These tasks include reasoning, problem-solving, learning, perception, language understanding, and more. AI encompasses various subfields, including machine learning, natural language processing, computer vision, robotics, and expert systems, among others.

## Types of AI

1. Narrow AI
2. AGI
3. Super intelligent AI

### Narrow AI

Narrow AI also know as weak Ai, designed to perform a specific task such as voice recognition *(Apple's Siri, Amazon's Alexa)*, image classification or recommendation systems. These systems are proficient in their scope but can't go beyond their fixed scope.

### AGI

AGI short for Artificial General Intelligence, also known as General or Strong AI. It possess human level intelligence & capable of performing intellectual tasks that human can do. It is like providing Robots the human intelligence.

### Super Intelligent AI

A Futuristic idea that would surpass human intelligence entirely. The ability to learn and understand any intellectual task.

#### Applications of AI

AI is in every field of life nowadays. But here are some common applications of AI.

- Computer Vision
- NLP
- Speech Recognition
- Speech Synthesis
- Image/video Generation

### Computer Vision

Deals with images and videos.

**Diffusion models** are studied under Computer Vision.
*Stable Diffusion*

- Dall-e-2
- Dall-e-3

## NLP

Short for **Natural Language Processing.** It focuses on language, enabling computers to comprehend analyze and generate human language.
**LLM's** are studied under NLP.

- ChatGPT
- Bard
- Bing AI

## Speech Recognition

Converts spoken language into text.

## Speech Synthesis

Converts text to speech.

## Machine Learning

Machine Learning is the subset of AI that focuses on enabling machines to learn from data without being explicitly programmed. It involves developing algorithms that can learn from and make predictions or decisions based on data. Machine learning algorithms are trained using large datasets to identify patterns and relationships in the data, which can then be used to make predictions or decisions on new data.

### Types of Machine Learning

1. Supervised Learning
2. UnSupervised Learning
3. ReInforcement Learning

#### Supervised Learning

Supervised learning is a type of machine learning that involves training a model on a labeled dataset. The model learns to map input data to the correct output based on the labels provided in the training data. Supervised learning is used for tasks such as classification and regression, where the goal is to predict a label or value based on input data.

#### UnSupervised Learning

Unsupervised learning is a type of machine learning that involves training a model on an unlabeled dataset. The model learns to identify patterns and relationships in the data without explicit guidance. Unsupervised learning is used for tasks such as clustering and dimensionality reduction, where the goal is to discover hidden structures in the data.

#### ReInforcement Learning

Reinforcement learning is a type of machine learning that involves training an agent to interact with an environment and learn from feedback in the form of rewards or penalties. The agent learns to take actions that maximize the cumulative reward over time. Reinforcement learning is used for tasks such as game playing and robotic control, where the goal is to learn a policy that guides the agent's behavior.

### Deep Learning

Deep learning is a subset of machine learning that focuses on training deep neural networks to learn from data. Deep neural networks are composed of multiple layers of interconnected nodes that can learn complex patterns and relationships in the data. Deep learning has been particularly successful in tasks such as image recognition, speech recognition, and natural language processing.

### Neural Networks

Neural networks are a type of deep learning model inspired by the structure of the human brain. They consist of interconnected nodes organized into layers, with each node performing a simple computation. Neural networks learn by adjusting the weights of the connections between nodes to minimize the error in the predictions made by the model.

### Convolutional Neural Networks (CNNs)

A **Convolutional Neural Network (CNN)** is a deep learning model widely used in **computer vision** tasks like image classification, object detection, and segmentation. It automatically learns spatial features through convolutional layers, which detect patterns such as edges and textures in images. Pooling layers reduce the dimensionality, while fully connected layers help classify the learned features. CNNs are highly effective in tasks requiring image analysis, such as facial recognition and medical imaging.

### Recurrent Neural Networks (RNNs)

Recurrent neural networks are a type of neural network designed for processing sequential data, such as text and time series. RNNs use recurrent connections to maintain a state that captures information about the sequence of inputs seen so far. RNNs have been used for tasks such as language modeling, machine translation, and speech recognition.

### Generative Adversarial Networks (GANs)

Generative adversarial networks are a type of deep learning model that consists of two neural networks: a **generator** and a **discriminator**. The generator learns to generate new data samples that are indistinguishable from real data, while the discriminator learns to distinguish between real and generated data. GANs have been used for tasks such as image generation and style transfer.

### Autoencoders

**Autoencoders** are a type of neural network used for **unsupervised learning** tasks like data compression and noise reduction. They consist of an encoder that reduces input data to a compressed, lower-dimensional representation and a decoder that reconstructs the original data from this compressed form. The network is trained to minimize the difference between the input and reconstructed output. Autoencoders are useful in applications like image denoising, dimensionality reduction, and anomaly detection.

## Transformers

**Transformers** are a neural network architecture primarily used in **natural language processing (NLP)** tasks, designed to handle sequential data while addressing limitations of previous models like RNNs. They use a mechanism called **self-attention**, which allows the model to weigh the importance of different words or tokens in a sequence, regardless of their position. Transformers are the foundation for models like GPT and BERT, excelling in tasks such as text translation, summarization, and language generation. Their ability to process entire sequences in parallel makes them highly efficient and scalable.

Learn more at: <https://github.com/Sarmad426/AI>
